{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Average forward pass time on CPU over 10 runs:\n",
      "  SR Model (5 blocks, 64 features): 144.865 ms\n",
      "  SR Model (10 blocks, 128 features): 907.161 ms\n",
      "  SRCNN: 25.320 ms\n",
      "  VSRnet without MC: 99.414 ms\n",
      "  VSRnet with optical flow MC: 135.218 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "# ---------------------------\n",
    "# My Models: SRModel (with Residual Blocks)\n",
    "# ---------------------------\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x + residual\n",
    "\n",
    "class SRModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features, num_res_blocks, upscale_factor):\n",
    "        super().__init__()\n",
    "        # Initial feature extraction\n",
    "        self.conv1 = nn.Conv2d(in_channels, features, kernel_size=3, padding=1)\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(features) for _ in range(num_res_blocks)])\n",
    "        # Final upscaling (using pixel shuffle)\n",
    "        self.conv2 = nn.Conv2d(features, out_channels * (upscale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        return x\n",
    "\n",
    "# ---------------------------\n",
    "# Dummy SRCNN model (based on [17])\n",
    "# ---------------------------\n",
    "class DummySRCNN(nn.Module):\n",
    "    def __init__(self, upscale_factor=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, stride=1, padding=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# ---------------------------\n",
    "# Optical Flow based Motion Compensation Module\n",
    "# ---------------------------\n",
    "class OpticalFlowMotionCompensation(nn.Module):\n",
    "    def __init__(self, k=0.125):\n",
    "        \"\"\"\n",
    "        k: constant used in the adaptive weighting, as in r = exp(-k * error)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, neighbor, center):\n",
    "        \"\"\"\n",
    "        neighbor, center: torch tensors of shape (B, 1, H, W) with type float32.\n",
    "        For each image in the batch, compute the optical flow from the neighbor to center using Farneback,\n",
    "        warp the neighbor frame, compute the per-pixel error and then apply adaptive motion compensation:\n",
    "        \n",
    "          y_amc(i,j) = (1 - r(i,j)) * y_center(i,j) + r(i,j) * y_warped(i,j),\n",
    "          \n",
    "        where r(i,j) = exp(-k * |y_center(i,j) - y_warped(i,j)|).\n",
    "        \"\"\"\n",
    "        B, C, H, W = neighbor.shape\n",
    "        compensated_list = []\n",
    "        # Process each image in the batch individually.\n",
    "        for i in range(B):\n",
    "            # Convert tensors to NumPy arrays.\n",
    "            neigh_np = neighbor[i, 0].detach().cpu().numpy().astype(np.float32)\n",
    "            cent_np = center[i, 0].detach().cpu().numpy().astype(np.float32)\n",
    "            \n",
    "            # Compute optical flow using Farneback.\n",
    "            # Note: In a full implementation you might tune these parameters further.\n",
    "            flow = cv2.calcOpticalFlowFarneback(neigh_np, cent_np, None,\n",
    "                                                pyr_scale=0.5, levels=3, winsize=15,\n",
    "                                                iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "            # Create remap coordinates.\n",
    "            grid_x, grid_y = np.meshgrid(np.arange(W), np.arange(H))\n",
    "            map_x = (grid_x + flow[..., 0]).astype(np.float32)\n",
    "            map_y = (grid_y + flow[..., 1]).astype(np.float32)\n",
    "            \n",
    "            # Warp the neighbor frame using the flow field.\n",
    "            warped = cv2.remap(neigh_np, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "            \n",
    "            # Compute per-pixel error.\n",
    "            error = np.abs(cent_np - warped)\n",
    "            r = np.exp(-self.k * error)\n",
    "            \n",
    "            # Adaptive motion compensation: weighted average between center and warped neighbor.\n",
    "            compensated = (1 - r) * cent_np + r * warped\n",
    "            \n",
    "            # Convert back to torch tensor.\n",
    "            compensated_tensor = torch.from_numpy(compensated).unsqueeze(0).unsqueeze(0)\n",
    "            compensated_list.append(compensated_tensor)\n",
    "        compensated_tensor = torch.cat(compensated_list, dim=0).to(neighbor.device)\n",
    "        return compensated_tensor\n",
    "\n",
    "# ---------------------------\n",
    "# VSRnet models\n",
    "# ---------------------------\n",
    "# VSRnet without motion compensation (as before)\n",
    "class DummyVSRNet(nn.Module):\n",
    "    def __init__(self, upscale_factor=4):\n",
    "        super().__init__()\n",
    "        # Separate convolutional layers for each frame.\n",
    "        self.conv1_f0 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f1 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f2 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        # For simplicity re-use conv1_f1 and conv1_f0 for frames 3 and 4.\n",
    "        self.conv2 = nn.Conv2d(320, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, stride=1, padding=2)\n",
    "        self.upscale_factor = upscale_factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 5, H, W)\n",
    "        h0 = self.conv1_f0(x[:, 0:1, :, :])\n",
    "        h1 = self.conv1_f1(x[:, 1:2, :, :])\n",
    "        h2 = self.conv1_f2(x[:, 2:3, :, :])\n",
    "        h3 = self.conv1_f1(x[:, 3:4, :, :])\n",
    "        h4 = self.conv1_f0(x[:, 4:5, :, :])\n",
    "        x_cat = torch.cat((h0, h1, h2, h3, h4), dim=1)\n",
    "        x_cat = F.relu(x_cat)\n",
    "        x_cat = F.relu(self.conv2(x_cat))\n",
    "        x_cat = self.conv3(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "# VSRnet with motion compensation using optical flow.\n",
    "class DummyVSRNetMCOptFlow(nn.Module):\n",
    "    def __init__(self, upscale_factor=4):\n",
    "        super().__init__()\n",
    "        # Instantiate the optical flow based motion compensation module.\n",
    "        self.mc = OpticalFlowMotionCompensation(k=0.125)\n",
    "        # Convolution layers for each frame.\n",
    "        self.conv1_f0 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f1 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f2 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv2 = nn.Conv2d(320, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, stride=1, padding=2)\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 5, H, W)\n",
    "        # Use the center frame (index 2) as reference.\n",
    "        center = x[:, 2:3, :, :]\n",
    "        # Apply optical flow based motion compensation to each neighboring frame.\n",
    "        x0 = self.mc(x[:, 0:1, :, :], center)\n",
    "        x1 = self.mc(x[:, 1:2, :, :], center)\n",
    "        # The center frame remains unchanged.\n",
    "        x2 = center\n",
    "        x3 = self.mc(x[:, 3:4, :, :], center)\n",
    "        x4 = self.mc(x[:, 4:5, :, :], center)\n",
    "        \n",
    "        h0 = self.conv1_f0(x0)\n",
    "        h1 = self.conv1_f1(x1)\n",
    "        h2 = self.conv1_f2(x2)\n",
    "        h3 = self.conv1_f1(x3)  # re-use conv1_f1 for simplicity\n",
    "        h4 = self.conv1_f0(x4)  # re-use conv1_f0 for simplicity\n",
    "        \n",
    "        x_cat = torch.cat((h0, h1, h2, h3, h4), dim=1)\n",
    "        x_cat = F.relu(x_cat)\n",
    "        x_cat = F.relu(self.conv2(x_cat))\n",
    "        x_cat = self.conv3(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "# ---------------------------\n",
    "# Timing utility function\n",
    "# ---------------------------\n",
    "def measure_time(model, input_tensor, num_runs=10):\n",
    "    # Warm-up runs (without logging time)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(3):\n",
    "            _ = model(input_tensor)\n",
    "    # Measure forward pass time\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            _ = model(input_tensor)\n",
    "    total_time = time.time() - start\n",
    "    avg_time = total_time / num_runs\n",
    "    return avg_time\n",
    "\n",
    "# ---------------------------\n",
    "# Main routine\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # set to cuda if available, else use cpu\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cpu')\n",
    "    else:\n",
    "        device = torch.device('cuda')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Instantiate models (using random weights)\n",
    "    model_small = SRModel(in_channels=9, out_channels=3, features=64, num_res_blocks=5, upscale_factor=4).to(device)\n",
    "    model_large = SRModel(in_channels=9, out_channels=3, features=128, num_res_blocks=10, upscale_factor=4).to(device)\n",
    "    srcnn = DummySRCNN(upscale_factor=4).to(device)\n",
    "    vsrnet_no_mc = DummyVSRNet(upscale_factor=4).to(device)\n",
    "    vsrnet_mc = DummyVSRNetMCOptFlow(upscale_factor=4).to(device)\n",
    "    \n",
    "    # Create dummy inputs:\n",
    "    # For SR models: input with 9 channels (3 frames × 3 channels) at 120×214 resolution.\n",
    "    input_sr = torch.randn(1, 9, 120, 214, device=device)\n",
    "    # For SRCNN: single-channel input (e.g., luminance)\n",
    "    input_srcnn = torch.randn(1, 1, 120, 214, device=device)\n",
    "    # For VSRnet models: 5 frames (single channel each)\n",
    "    input_vsr = torch.randn(1, 5, 120, 214, device=device)\n",
    "    \n",
    "    # Number of forward passes to average (reduced here since optical flow is more expensive)\n",
    "    num_runs = 10\n",
    "    time_small = measure_time(model_small, input_sr, num_runs)\n",
    "    time_large = measure_time(model_large, input_sr, num_runs)\n",
    "    time_srcnn = measure_time(srcnn, input_srcnn, num_runs)\n",
    "    time_vsr_no_mc = measure_time(vsrnet_no_mc, input_vsr, num_runs)\n",
    "    time_vsr_mc = measure_time(vsrnet_mc, input_vsr, num_runs)\n",
    "    \n",
    "    # Log the average forward pass times (in milliseconds)\n",
    "    print(f\"Average forward pass time on CPU over {num_runs} runs:\")\n",
    "    print(f\"  SR Model (5 blocks, 64 features): {time_small * 1000:.3f} ms\")\n",
    "    print(f\"  SR Model (10 blocks, 128 features): {time_large * 1000:.3f} ms\")\n",
    "    print(f\"  SRCNN: {time_srcnn * 1000:.3f} ms\")\n",
    "    print(f\"  VSRnet without MC: {time_vsr_no_mc * 1000:.3f} ms\")\n",
    "    print(f\"  VSRnet with optical flow MC: {time_vsr_mc * 1000:.3f} ms\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Average forward pass time on CPU over 50 runs:\n",
      "  SR Model (5 blocks, 64 features): 8.879 ms\n",
      "  SR Model (10 blocks, 128 features): 41.924 ms\n",
      "  SRCNN: 5.209 ms\n",
      "  VSRnet without MC: 486.388 ms\n",
      "  VSRnet with optical flow MC: 1412.317 ms\n",
      "  Two-stage SR Model (Base + Refinement): 94.388 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# ---------------------------\n",
    "# Residual Block Definition\n",
    "# ---------------------------\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x + residual\n",
    "\n",
    "# ---------------------------\n",
    "# SRModel (with Residual Blocks)\n",
    "# ---------------------------\n",
    "class SRModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features, num_res_blocks, upscale_factor):\n",
    "        super().__init__()\n",
    "        # Initial feature extraction\n",
    "        self.conv1 = nn.Conv2d(in_channels, features, kernel_size=3, padding=1)\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(features) for _ in range(num_res_blocks)])\n",
    "        # Final upscaling (using pixel shuffle)\n",
    "        self.conv2 = nn.Conv2d(features, out_channels * (upscale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        return x\n",
    "\n",
    "# ---------------------------\n",
    "# Dummy SRCNN model (based on [17])\n",
    "# ---------------------------\n",
    "class DummySRCNN(nn.Module):\n",
    "    def __init__(self, upscale_factor=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, stride=1, padding=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# ---------------------------\n",
    "# Optical Flow based Motion Compensation Module\n",
    "# ---------------------------\n",
    "class OpticalFlowMotionCompensation(nn.Module):\n",
    "    def __init__(self, k=0.125):\n",
    "        \"\"\"\n",
    "        k: constant used in the adaptive weighting, as in r = exp(-k * error)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, neighbor, center):\n",
    "        \"\"\"\n",
    "        neighbor, center: torch tensors of shape (B, 1, H, W) with type float32.\n",
    "        For each image in the batch, compute the optical flow from the neighbor to center using Farneback,\n",
    "        warp the neighbor frame, compute the per-pixel error and then apply adaptive motion compensation:\n",
    "        \n",
    "          y_amc(i,j) = (1 - r(i,j)) * y_center(i,j) + r(i,j) * y_warped(i,j),\n",
    "          \n",
    "        where r(i,j) = exp(-k * |y_center(i,j) - y_warped(i,j)|).\n",
    "        \"\"\"\n",
    "        B, C, H, W = neighbor.shape\n",
    "        compensated_list = []\n",
    "        # Process each image in the batch individually.\n",
    "        for i in range(B):\n",
    "            # Convert tensors to NumPy arrays.\n",
    "            neigh_np = neighbor[i, 0].detach().cpu().numpy().astype(np.float32)\n",
    "            cent_np = center[i, 0].detach().cpu().numpy().astype(np.float32)\n",
    "            \n",
    "            # Compute optical flow using Farneback.\n",
    "            flow = cv2.calcOpticalFlowFarneback(neigh_np, cent_np, None,\n",
    "                                                pyr_scale=0.5, levels=3, winsize=15,\n",
    "                                                iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "            # Create remap coordinates.\n",
    "            grid_x, grid_y = np.meshgrid(np.arange(W), np.arange(H))\n",
    "            map_x = (grid_x + flow[..., 0]).astype(np.float32)\n",
    "            map_y = (grid_y + flow[..., 1]).astype(np.float32)\n",
    "            \n",
    "            # Warp the neighbor frame using the flow field.\n",
    "            warped = cv2.remap(neigh_np, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "            \n",
    "            # Compute per-pixel error.\n",
    "            error = np.abs(cent_np - warped)\n",
    "            r = np.exp(-self.k * error)\n",
    "            \n",
    "            # Adaptive motion compensation: weighted average between center and warped neighbor.\n",
    "            compensated = (1 - r) * cent_np + r * warped\n",
    "            \n",
    "            # Convert back to torch tensor.\n",
    "            compensated_tensor = torch.from_numpy(compensated).unsqueeze(0).unsqueeze(0)\n",
    "            compensated_list.append(compensated_tensor)\n",
    "        compensated_tensor = torch.cat(compensated_list, dim=0).to(neighbor.device)\n",
    "        return compensated_tensor\n",
    "\n",
    "# ---------------------------\n",
    "# VSRnet models\n",
    "# ---------------------------\n",
    "# VSRnet without motion compensation\n",
    "class DummyVSRNet(nn.Module):\n",
    "    def __init__(self, upscale_factor=4):\n",
    "        super().__init__()\n",
    "        # Separate convolutional layers for each frame.\n",
    "        self.conv1_f0 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f1 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f2 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        # For simplicity re-use conv1_f1 and conv1_f0 for frames 3 and 4.\n",
    "        self.conv2 = nn.Conv2d(320, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, stride=1, padding=2)\n",
    "        self.upscale_factor = upscale_factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 5, H, W)\n",
    "        h0 = self.conv1_f0(x[:, 0:1, :, :])\n",
    "        h1 = self.conv1_f1(x[:, 1:2, :, :])\n",
    "        h2 = self.conv1_f2(x[:, 2:3, :, :])\n",
    "        h3 = self.conv1_f1(x[:, 3:4, :, :])\n",
    "        h4 = self.conv1_f0(x[:, 4:5, :, :])\n",
    "        x_cat = torch.cat((h0, h1, h2, h3, h4), dim=1)\n",
    "        x_cat = F.relu(x_cat)\n",
    "        x_cat = F.relu(self.conv2(x_cat))\n",
    "        x_cat = self.conv3(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "# VSRnet with motion compensation using optical flow.\n",
    "class DummyVSRNetMCOptFlow(nn.Module):\n",
    "    def __init__(self, upscale_factor=4):\n",
    "        super().__init__()\n",
    "        # Instantiate the optical flow based motion compensation module.\n",
    "        self.mc = OpticalFlowMotionCompensation(k=0.125)\n",
    "        # Convolution layers for each frame.\n",
    "        self.conv1_f0 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f1 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv1_f2 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv2 = nn.Conv2d(320, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, stride=1, padding=2)\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 5, H, W)\n",
    "        # Use the center frame (index 2) as reference.\n",
    "        center = x[:, 2:3, :, :]\n",
    "        # Apply optical flow based motion compensation to each neighboring frame.\n",
    "        x0 = self.mc(x[:, 0:1, :, :], center)\n",
    "        x1 = self.mc(x[:, 1:2, :, :], center)\n",
    "        # The center frame remains unchanged.\n",
    "        x2 = center\n",
    "        x3 = self.mc(x[:, 3:4, :, :], center)\n",
    "        x4 = self.mc(x[:, 4:5, :, :], center)\n",
    "        \n",
    "        h0 = self.conv1_f0(x0)\n",
    "        h1 = self.conv1_f1(x1)\n",
    "        h2 = self.conv1_f2(x2)\n",
    "        h3 = self.conv1_f1(x3)  # re-use conv1_f1 for simplicity\n",
    "        h4 = self.conv1_f0(x4)  # re-use conv1_f0 for simplicity\n",
    "        \n",
    "        x_cat = torch.cat((h0, h1, h2, h3, h4), dim=1)\n",
    "        x_cat = F.relu(x_cat)\n",
    "        x_cat = F.relu(self.conv2(x_cat))\n",
    "        x_cat = self.conv3(x_cat)\n",
    "        return x_cat\n",
    "\n",
    "# ---------------------------\n",
    "# New Two-Stage SR Model\n",
    "# ---------------------------\n",
    "# The base model (first stage) is the same as SRModel above.\n",
    "# New refinement network (second stage) to boost high-frequency details.\n",
    "class RefinementNet(nn.Module):\n",
    "    def __init__(self, channels=3, features=64, num_res_blocks=3):\n",
    "        super(RefinementNet, self).__init__()\n",
    "        self.conv_in = nn.Conv2d(channels, features, kernel_size=3, padding=1)\n",
    "        # A few residual blocks for texture refinement\n",
    "        res_blocks = [ResidualBlock(features) for _ in range(num_res_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "        self.conv_out = nn.Conv2d(features, channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv_in(x))\n",
    "        out = self.res_blocks(out)\n",
    "        out = self.conv_out(out)\n",
    "        # Residual connection: refine rather than re-predict entirely.\n",
    "        return x + out\n",
    "\n",
    "# Composite model that feeds the output of the base model into the refinement network.\n",
    "class TwoStageSRModel(nn.Module):\n",
    "    def __init__(self, base_model, refinement_model):\n",
    "        super(TwoStageSRModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.refinement_model = refinement_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        base_output = self.base_model(x)\n",
    "        refined_output = self.refinement_model(base_output)\n",
    "        return refined_output\n",
    "\n",
    "# ---------------------------\n",
    "# Timing utility function\n",
    "# ---------------------------\n",
    "def measure_time(model, input_tensor, num_runs=10):\n",
    "    # Warm-up runs (without logging time)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(3):\n",
    "            _ = model(input_tensor)\n",
    "    # Measure forward pass time\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            _ = model(input_tensor)\n",
    "    total_time = time.time() - start\n",
    "    avg_time = total_time / num_runs\n",
    "    return avg_time\n",
    "\n",
    "# ---------------------------\n",
    "# Main routine\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # set to cuda if available, else use cpu (note: this example uses cpu if cuda is available)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Instantiate models (using random weights)\n",
    "    model_small = SRModel(in_channels=9, out_channels=3, features=64, num_res_blocks=5, upscale_factor=4).to(device)\n",
    "    model_large = SRModel(in_channels=9, out_channels=3, features=128, num_res_blocks=10, upscale_factor=4).to(device)\n",
    "    srcnn = DummySRCNN(upscale_factor=4).to(device)\n",
    "    vsrnet_no_mc = DummyVSRNet(upscale_factor=4).to(device)\n",
    "    vsrnet_mc = DummyVSRNetMCOptFlow(upscale_factor=4).to(device)\n",
    "    \n",
    "    # Instantiate the new two-stage model:\n",
    "    # Base model: same as SRModel (5 blocks, 64 features)\n",
    "    base_model = SRModel(in_channels=9, out_channels=3, features=64, num_res_blocks=5, upscale_factor=4).to(device)\n",
    "    # Refinement network: 3 residual blocks for texture refinement.\n",
    "    refinement_net = RefinementNet(channels=3, features=64, num_res_blocks=3).to(device)\n",
    "    two_stage = TwoStageSRModel(base_model, refinement_net).to(device)\n",
    "    \n",
    "    # Create dummy inputs:\n",
    "    # For SR models and two-stage model: input with 9 channels (3 frames × 3 channels) at 120×214 resolution.\n",
    "    input_sr = torch.randn(1, 9, 120, 214, device=device)\n",
    "    # For SRCNN: single-channel input (e.g., luminance)\n",
    "    input_srcnn = torch.randn(1, 1, 120, 214, device=device)\n",
    "    # For VSRnet models: 5 frames (single channel each)\n",
    "    input_vsr = torch.randn(1, 5, 120, 214, device=device)\n",
    "    \n",
    "    # Number of forward passes to average\n",
    "    num_runs = 50\n",
    "    time_small = measure_time(model_small, input_sr, num_runs)\n",
    "    time_large = measure_time(model_large, input_sr, num_runs)\n",
    "    time_srcnn = measure_time(srcnn, input_srcnn, num_runs)\n",
    "    time_vsr_no_mc = measure_time(vsrnet_no_mc, input_vsr, num_runs)\n",
    "    time_vsr_mc = measure_time(vsrnet_mc, input_vsr, num_runs)\n",
    "    time_two_stage = measure_time(two_stage, input_sr, num_runs)\n",
    "    \n",
    "    # Log the average forward pass times (in milliseconds)\n",
    "    print(f\"Average forward pass time on CPU over {num_runs} runs:\")\n",
    "    print(f\"  SR Model (5 blocks, 64 features): {time_small * 1000:.3f} ms\")\n",
    "    print(f\"  SR Model (10 blocks, 128 features): {time_large * 1000:.3f} ms\")\n",
    "    print(f\"  SRCNN: {time_srcnn * 1000:.3f} ms\")\n",
    "    print(f\"  VSRnet without MC: {time_vsr_no_mc * 1000:.3f} ms\")\n",
    "    print(f\"  VSRnet with optical flow MC: {time_vsr_mc * 1000:.3f} ms\")\n",
    "    print(f\"  Two-stage SR Model (Base + Refinement): {time_two_stage * 1000:.3f} ms\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
