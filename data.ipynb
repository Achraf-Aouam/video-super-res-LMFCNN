{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Download Videos from Vimeo (Improved Version)\n",
    "\n",
    "\n",
    "\n",
    "# Create directories to store videos and frames\n",
    "os.makedirs('videos', exist_ok=True)\n",
    "os.makedirs('frames/HR', exist_ok=True)\n",
    "os.makedirs('frames/LR', exist_ok=True)\n",
    "\n",
    "def download_vimeo_video(link, output_file, attempt=1, max_attempts=3):\n",
    "    \"\"\"\n",
    "    Download a single video with better error handling and retries\n",
    "    \"\"\"\n",
    "    # First try yt-dlp which is more up-to-date and has better Vimeo support\n",
    "    try:\n",
    "        cmd = [\n",
    "            'yt-dlp',  # Use yt-dlp instead of youtube-dl\n",
    "            link,\n",
    "            '-f', 'bestvideo[height<=1080][ext=mp4]+bestaudio[ext=m4a]/mp4',  # Limit to 1080p max\n",
    "            '-o', output_file,\n",
    "            '--no-warnings',\n",
    "            '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            '--add-header', 'Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            '--add-header', 'Accept-Language:en-US,en;q=0.5'\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)\n",
    "        \n",
    "        # Check if download was successful\n",
    "        if os.path.exists(output_file) and os.path.getsize(output_file) > 100000:\n",
    "            return True\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        # yt-dlp not installed, try youtube-dl\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        if attempt < max_attempts:\n",
    "            print(f\"Retry {attempt}/{max_attempts} for {link} due to: {str(e)}\")\n",
    "            time.sleep(5)  # Wait before retry\n",
    "            return download_vimeo_video(link, output_file, attempt + 1, max_attempts)\n",
    "        return False\n",
    "    \n",
    "    # If yt-dlp failed or not installed, try youtube-dl\n",
    "    try:\n",
    "        cmd = [\n",
    "            'youtube-dl',\n",
    "            link,\n",
    "            '--no-check-certificate',  # Skip certificate validation\n",
    "            '-f', 'bestvideo[height<=1080][ext=mp4]+bestaudio[ext=m4a]/mp4/best[height<=1080]',\n",
    "            '-o', output_file,\n",
    "            '--no-warnings',\n",
    "            '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)\n",
    "        \n",
    "        # Check if download was successful\n",
    "        if os.path.exists(output_file) and os.path.getsize(output_file) > 100000:\n",
    "            return True\n",
    "        else:\n",
    "            if attempt < max_attempts:\n",
    "                print(f\"Retry {attempt}/{max_attempts} for {link}\")\n",
    "                time.sleep(5)  # Wait before retry\n",
    "                return download_vimeo_video(link, output_file, attempt + 1, max_attempts)\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        if attempt < max_attempts:\n",
    "            print(f\"Retry {attempt}/{max_attempts} for {link} due to: {str(e)}\")\n",
    "            time.sleep(5)  # Wait before retry\n",
    "            return download_vimeo_video(link, output_file, attempt + 1, max_attempts)\n",
    "        return False\n",
    "\n",
    "def download_videos(links_file, output_dir='videos', target_count=1000, max_attempts=2000):\n",
    "    \"\"\"\n",
    "    Download videos from links in a text file until reaching target_count successful downloads\n",
    "    \"\"\"\n",
    "    # Read the links file\n",
    "    with open(links_file, 'r') as f:\n",
    "        links = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    # Shuffle links to get a random sample\n",
    "    random.shuffle(links)\n",
    "    \n",
    "    successful_downloads = 0\n",
    "    attempted_links = 0\n",
    "    \n",
    "    print(f\"Starting downloads, aiming for {target_count} videos...\")\n",
    "    \n",
    "    for link in tqdm(links):\n",
    "        if successful_downloads >= target_count or attempted_links >= max_attempts:\n",
    "            break\n",
    "            \n",
    "        attempted_links += 1\n",
    "        video_id = link.split('/')[-1]\n",
    "        output_file = os.path.join(output_dir, f\"{video_id}.mp4\")\n",
    "        \n",
    "        # Skip if already downloaded\n",
    "        if os.path.exists(output_file) and os.path.getsize(output_file) > 100000:\n",
    "            successful_downloads += 1\n",
    "            continue\n",
    "        \n",
    "        # Try to download with better error handling\n",
    "        success = download_vimeo_video(link, output_file)\n",
    "        \n",
    "        if success:\n",
    "            successful_downloads += 1\n",
    "            print(f\"Successfully downloaded {successful_downloads}/{target_count}: {video_id}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {link}\")\n",
    "        \n",
    "        # Add a small delay to avoid rate limiting\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return successful_downloads\n",
    "\n",
    "# Check if yt-dlp is installed, otherwise recommend it\n",
    "try:\n",
    "    subprocess.run(['yt-dlp', '--version'], capture_output=True)\n",
    "    print(\"Using yt-dlp for downloads\")\n",
    "except FileNotFoundError:\n",
    "    print(\"yt-dlp not found. For better results, install it with: pip install yt-dlp\")\n",
    "    print(\"Falling back to youtube-dl\")\n",
    "\n",
    "# Alternative approach: use a small test set of videos if downloading fails\n",
    "def create_test_dataset():\n",
    "    \"\"\"Create a small test dataset using video files from the system or sample sources\"\"\"\n",
    "    print(\"Creating a small test dataset for development...\")\n",
    "    \n",
    "    # Try to find some sample videos on the system\n",
    "    sample_dirs = [\n",
    "        '/usr/share/example-videos',  # Some Linux systems have sample videos\n",
    "        os.path.expanduser('~/Videos'),  # User's video directory\n",
    "        '.'  # Current directory\n",
    "    ]\n",
    "    \n",
    "    found_videos = []\n",
    "    for directory in sample_dirs:\n",
    "        if os.path.exists(directory):\n",
    "            for file in os.listdir(directory):\n",
    "                if file.endswith(('.mp4', '.mkv', '.avi', '.mov')):\n",
    "                    video_path = os.path.join(directory, file)\n",
    "                    dest_path = os.path.join('videos', file)\n",
    "                    if os.path.exists(video_path) and os.path.getsize(video_path) > 1000000:  # >1MB\n",
    "                        if not os.path.exists(dest_path):\n",
    "                            # Copy file to videos directory\n",
    "                            try:\n",
    "                                import shutil\n",
    "                                shutil.copy2(video_path, dest_path)\n",
    "                                found_videos.append(dest_path)\n",
    "                                print(f\"Added video for testing: {file}\")\n",
    "                            except:\n",
    "                                pass\n",
    "    \n",
    "    # If no videos found, create a synthetic test video\n",
    "    if not found_videos:\n",
    "        try:\n",
    "            # Create a simple 10-second test video\n",
    "            print(\"Creating synthetic test video...\")\n",
    "            import numpy as np\n",
    "            import cv2\n",
    "            \n",
    "            output_path = os.path.join('videos', 'synthetic_test.mp4')\n",
    "            \n",
    "            # Create a 10 second video with moving shapes\n",
    "            fps = 30\n",
    "            width, height = 640, 480\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "            \n",
    "            for i in range(300):  # 10 seconds at 30fps\n",
    "                frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "                \n",
    "                # Moving circle\n",
    "                cx = int(width/2 + width/4 * np.sin(i/30))\n",
    "                cy = int(height/2 + height/4 * np.cos(i/30))\n",
    "                cv2.circle(frame, (cx, cy), 50, (0, 0, 255), -1)\n",
    "                \n",
    "                # Moving rectangle\n",
    "                rx = int(width/2 + width/5 * np.cos(i/40))\n",
    "                ry = int(height/2 + height/5 * np.sin(i/40))\n",
    "                cv2.rectangle(frame, (rx-40, ry-40), (rx+40, ry+40), (0, 255, 0), -1)\n",
    "                \n",
    "                # Add some text\n",
    "                cv2.putText(frame, f\"Frame {i}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                \n",
    "                out.write(frame)\n",
    "            \n",
    "            out.release()\n",
    "            found_videos.append(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating synthetic video: {e}\")\n",
    "    \n",
    "    return len(found_videos) > 0\n",
    "\n",
    "# Load the links file and download videos\n",
    "links_file = 'vimeo_links.txt'  # Replace with your links file\n",
    "\n",
    "if os.path.exists(links_file):\n",
    "    successful_count = download_videos(links_file, target_count=1000)\n",
    "    print(f\"Downloaded {successful_count} videos successfully\")\n",
    "    \n",
    "    # If not enough videos downloaded, create test dataset\n",
    "    if successful_count < 10:\n",
    "        print(\"Not enough videos downloaded. Creating test dataset...\")\n",
    "        create_test_dataset()\n",
    "else:\n",
    "    print(f\"Links file {links_file} not found. Creating test dataset...\")\n",
    "    create_test_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos available: 711\n"
     ]
    }
   ],
   "source": [
    "# Get list of downloaded videos\n",
    "video_files = [os.path.join('videos', f) for f in os.listdir('videos') if f.endswith(('.mp4', '.mkv', '.avi', '.mov'))]\n",
    "print(f\"Total videos available: {len(video_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc3fa5d70c47d4a367f0c119a03f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2125 sequences\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Extract Frame Sequences\n",
    "\n",
    "\n",
    "\n",
    "def extract_frame_sequences(video_files, output_dir='frames/HR', sequences_per_video=3, sequence_length=5):\n",
    "    \"\"\"\n",
    "    Extract random frame sequences from videos\n",
    "    \"\"\"\n",
    "    # Create sequence record\n",
    "    sequence_data = []\n",
    "    \n",
    "    for video_idx, video_path in enumerate(tqdm(video_files)):\n",
    "        try:\n",
    "            # Open video file\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            \n",
    "            # Check if video opened successfully\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Error opening video: {video_path}\")\n",
    "                continue\n",
    "                \n",
    "            # Get video properties\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            \n",
    "            # Skip very short videos or low resolution videos\n",
    "            if total_frames < 30 or width < 480 or height < 360:\n",
    "                cap.release()\n",
    "                continue\n",
    "                \n",
    "            # Calculate valid starting points for sequences (need sequence_length consecutive frames)\n",
    "            valid_starts = max(0, total_frames - sequence_length)\n",
    "            \n",
    "            if valid_starts <= 0:\n",
    "                cap.release()\n",
    "                continue\n",
    "                \n",
    "            # Generate random starting points for sequences\n",
    "            # Make sure sequences don't overlap by enforcing minimum gap\n",
    "            min_gap = 30  # At least 30 frames between sequences\n",
    "            sequence_starts = []\n",
    "            \n",
    "            attempts = 0\n",
    "            while len(sequence_starts) < sequences_per_video and attempts < 20:\n",
    "                attempts += 1\n",
    "                candidate = random.randint(0, valid_starts)\n",
    "                \n",
    "                # Check if candidate is far enough from existing starts\n",
    "                if all(abs(candidate - start) >= min_gap for start in sequence_starts):\n",
    "                    sequence_starts.append(candidate)\n",
    "            \n",
    "            # Extract the sequences\n",
    "            for seq_idx, start_frame in enumerate(sequence_starts):\n",
    "                # Create sequence directory\n",
    "                sequence_dir = os.path.join(output_dir, f\"video_{video_idx:04d}_seq_{seq_idx}\")\n",
    "                os.makedirs(sequence_dir, exist_ok=True)\n",
    "                \n",
    "                # Set video to starting frame\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "                \n",
    "                # Extract sequence_length frames\n",
    "                sequence_frames = []\n",
    "                for frame_idx in range(sequence_length):\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                        \n",
    "                    # Save frame\n",
    "                    frame_path = os.path.join(sequence_dir, f\"frame_{frame_idx:02d}.png\")\n",
    "                    cv2.imwrite(frame_path, frame)\n",
    "                    sequence_frames.append(frame_path)\n",
    "                \n",
    "                # Record sequence information\n",
    "                if len(sequence_frames) == sequence_length:\n",
    "                    sequence_data.append({\n",
    "                        'video_file': os.path.basename(video_path),\n",
    "                        'sequence_dir': sequence_dir,\n",
    "                        'start_frame': start_frame,\n",
    "                        'frames': sequence_frames,\n",
    "                        'width': width,\n",
    "                        'height': height,\n",
    "                        'fps': fps\n",
    "                    })\n",
    "            \n",
    "            cap.release()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_path}: {str(e)}\")\n",
    "    \n",
    "    # Save sequence metadata\n",
    "    sequence_df = pd.DataFrame(sequence_data)\n",
    "    sequence_df.to_csv('frame_sequences.csv', index=False)\n",
    "    \n",
    "    return sequence_df\n",
    "\n",
    "# Extract frame sequences\n",
    "sequence_df = extract_frame_sequences(video_files)\n",
    "print(f\"Extracted {len(sequence_df)} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2125 sequences from CSV\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the previously saved sequence data from CSV\n",
    "\n",
    "sequence_df = pd.read_csv('frame_sequences.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Convert string representation of list back to actual list for 'frames' column\n",
    "\n",
    "sequence_df['frames'] = sequence_df['frames'].apply(eval)  # This converts the string representation back to a list\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(sequence_df)} sequences from CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23309abe0b2441aa3a193b99d80586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created LR frames for all sequences with 4x downscaling and subtle quality degradation\n",
      "Created data split: 1700 train, 425 test sequences\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create LR Frames from HR Frames\n",
    "\n",
    "\n",
    "\n",
    "def create_lr_frames(sequence_df, hr_dir='frames/HR', lr_dir='frames/LR', \n",
    "                     target_hr_size=(480, 854), target_lr_size=(120, 214)):  # Changed to 4x downscaling\n",
    "    \"\"\"\n",
    "    Create low-resolution frames from high-resolution frames\n",
    "    - Resizes HR frames to standard size (480p)\n",
    "    - Creates corresponding LR frames by downscaling (4x factor)\n",
    "    - Adds subtle degradation to mimic low bandwidth video\n",
    "    \"\"\"\n",
    "    # Make sure directories exist\n",
    "    os.makedirs(lr_dir, exist_ok=True)\n",
    "    \n",
    "    # Function for high-quality downscaling with subtle degradation\n",
    "    def downscale_with_degradation(img, target_size):\n",
    "        # Step 1: Basic downscale with INTER_AREA (clean downscaling)\n",
    "        downscaled = cv2.resize(img, target_size[::-1], interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Step 2: Apply subtle degradation to mimic low bandwidth\n",
    "        # Mild JPEG compression artifacts\n",
    "        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 92]\n",
    "        _, encoded_img = cv2.imencode('.jpg', downscaled, encode_param)\n",
    "        degraded = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Subtle color subsampling effect (very mild)\n",
    "        if random.random() < 0.5:  # Only apply to some frames for natural variation\n",
    "            # Convert to YCrCb, slightly blur chroma channels, convert back\n",
    "            ycrcb = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
    "            channels = list(cv2.split(ycrcb))  # Convert tuple to list so we can modify it\n",
    "            \n",
    "            # Apply very slight blur to chroma channels\n",
    "            channels[1] = cv2.GaussianBlur(channels[1], (3, 3), 0.5)\n",
    "            channels[2] = cv2.GaussianBlur(channels[2], (3, 3), 0.5)\n",
    "            \n",
    "            ycrcb = cv2.merge(channels)\n",
    "            degraded = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "        \n",
    "        return degraded\n",
    "    \n",
    "    for _, row in tqdm(sequence_df.iterrows(), total=len(sequence_df)):\n",
    "        # Get sequence directory name\n",
    "        seq_name = os.path.basename(row['sequence_dir'])\n",
    "        \n",
    "        # Create corresponding LR directory\n",
    "        lr_seq_dir = os.path.join(lr_dir, seq_name)\n",
    "        os.makedirs(lr_seq_dir, exist_ok=True)\n",
    "        \n",
    "        # Process each frame in the sequence\n",
    "        for frame_path in row['frames']:\n",
    "            # Get frame filename\n",
    "            frame_name = os.path.basename(frame_path)\n",
    "            \n",
    "            # Load HR frame\n",
    "            hr_frame = cv2.imread(frame_path)\n",
    "            if hr_frame is None:\n",
    "                print(f\"Error loading frame: {frame_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Resize HR frame to standard size (480p) with good quality\n",
    "            hr_frame = cv2.resize(hr_frame, target_hr_size[::-1], interpolation=cv2.INTER_LANCZOS4)\n",
    "            \n",
    "            # Save standardized HR frame\n",
    "            std_hr_path = os.path.join(os.path.dirname(frame_path), frame_name)\n",
    "            cv2.imwrite(std_hr_path, hr_frame)\n",
    "            \n",
    "            # Create LR frame with 4x downscaling and subtle degradation\n",
    "            lr_frame = downscale_with_degradation(hr_frame, target_lr_size)\n",
    "            \n",
    "            # Save LR frame with high quality\n",
    "            lr_path = os.path.join(lr_seq_dir, frame_name)\n",
    "            cv2.imwrite(lr_path, lr_frame, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    \n",
    "    print(\"Created LR frames for all sequences with 4x downscaling and subtle quality degradation\")\n",
    "    \n",
    "    # Create train/test split\n",
    "    sequence_dirs = sequence_df['sequence_dir'].apply(os.path.basename).unique()\n",
    "    random.shuffle(sequence_dirs)\n",
    "    \n",
    "    split_idx = int(len(sequence_dirs) * 0.8)  # 80% train, 20% test\n",
    "    train_sequences = sequence_dirs[:split_idx]\n",
    "    test_sequences = sequence_dirs[split_idx:]\n",
    "    \n",
    "    # Save train/test split - using concat instead of append (which is deprecated)\n",
    "    pd.concat([\n",
    "        pd.DataFrame({'sequence': train_sequences, 'split': 'train'}),\n",
    "        pd.DataFrame({'sequence': test_sequences, 'split': 'test'})\n",
    "    ]).to_csv('data_split.csv', index=False)\n",
    "    \n",
    "    print(f\"Created data split: {len(train_sequences)} train, {len(test_sequences)} test sequences\")\n",
    "\n",
    "# Create LR frames from HR frames\n",
    "# We'll use 480p for HR and 120p for LR (4x upscaling)\n",
    "create_lr_frames(sequence_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
